# -*- coding: utf-8 -*-
"""Text_cleaning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b-7OlleXoXYG1yMNytL9KGgBB-eiC5Is
"""

import re
import nltk
nltk.download('wordnet')
nltk.download('punkt_tab')
from nltk.tokenize import word_tokenize
nltk.download('stopwords')

# Download the punkt tokenizer
from nltk.corpus import stopwords

from nltk.stem import WordNetLemmatizer
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    if not isinstance(text, str):       # Handle non-string inputs
        return ""
    text = text.lower()                 # Convert to lowercase
    text = re.sub(r'http\S+', '', text) # Remove URLs
    text = re.sub(r'@\w+', '', text)    # Remove mentions
    text = re.sub(r'#\w+', '', text)    # Remove hashtags
    text = re.sub(r'\d+', '', text)     # Remove numbers
    text = re.sub(r'[^\w\s]', '', text) # Remove punctuation
    tokens = word_tokenize(text)        # Tokenize
    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]

    return " ".join(cleaned_tokens)     # Return cleaned text as a string